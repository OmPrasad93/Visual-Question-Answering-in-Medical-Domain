# Visual-Question-Answering-in-Medical-Domain
VQA is a multidisciplinary problem which combines two modalities: text and image. It requires computer vision and NLP techniques (probably, reasoning techniques too). The task is to answer a question correctly, where the question is accompanied by an image on which it is based.

The problem statement is as follows: “Given a medical image accompanied with a clinically relevant question,
participating systems are tasked with answering the question based on the visual image
content”.


Baseline Model Architecture
![alt text](https://github.com/nehareddyg/Visual-Question-Answering-in-Medical-Domain/blob/master/model.png)

Please refer to the file "AMP report.pdf" for implementation details.

Contributors: 
G Neha (nehareddyg)
Meghana Kotagiri(meghanakotagiri)
 
