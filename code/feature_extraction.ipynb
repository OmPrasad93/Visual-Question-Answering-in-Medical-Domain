{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import skimage\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import tensorflow.python.platform\n",
    "from keras.preprocessing import sequence\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Give csv of the dataset for which feature extraction has to be performed\n",
    "df = pd.read_csv('/home/neha/sem8/AMP/assignment-2/vqa assignment/VQAMed2018Valid/VQAMed2018Valid-QA.csv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df[[0,1,2]]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns=['Serialno','imageno','question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to remove inputs where answers span across multiple columns  \n",
    "boolmat=[]\n",
    "for i in range(0,len(df)):\n",
    "    boolmat.append(df['question'].iloc[i][len(df['question'].iloc[i])-1]=='?')\n",
    "df=df[boolmat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path to VGG model \n",
    "vgg_path = './vqa assignment/model/vgg16-20160129.tfmodel'\n",
    "#path to directory that contains images\n",
    "img_path='./vqa assignment/VQAMed2018Valid/VQAMed2018Valid-images'\n",
    "def crop_image(x, target_height=227, target_width=227, as_float=True):\n",
    "    image = cv2.imread(x)\n",
    "    if as_float:\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.tile(image[:,:,None], 3)\n",
    "    elif len(image.shape) == 4:\n",
    "        image = image[:,:,:,0]\n",
    "\n",
    "    height, width, rgb = image.shape\n",
    "    if width == height:\n",
    "        resized_image = cv2.resize(image, (target_height,target_width))\n",
    "\n",
    "    elif height < width:\n",
    "        resized_image = cv2.resize(image, (int(width * float(target_height)/height), target_width))\n",
    "        cropping_length = int((resized_image.shape[1] - target_height) / 2)\n",
    "        resized_image = resized_image[:,cropping_length:resized_image.shape[1] - cropping_length]\n",
    "\n",
    "    else:\n",
    "        resized_image = cv2.resize(image, (target_height, int(height * float(target_width) / width)))\n",
    "        cropping_length = int((resized_image.shape[0] - target_width) / 2)\n",
    "        resized_image = resized_image[cropping_length:resized_image.shape[0] - cropping_length,:]\n",
    "\n",
    "    return cv2.resize(resized_image, (target_height, target_width))\n",
    "\n",
    "def read_image(path):\n",
    "    img = crop_image(path, target_height=224, target_width=224)\n",
    "    if img.shape[2] == 4:\n",
    "        img = img[:,:,:3]\n",
    "    img = img[None, ...]\n",
    "    return img\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with open(vgg_path,'rb') as f:\n",
    "        fileContent = f.read()\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(fileContent)\n",
    "final_array_test = []\n",
    "images = tf.placeholder(\"float32\", [1, 224, 224, 3])\n",
    "tf.import_graph_def(graph_def, input_map={\"images\":images})\n",
    "graph = tf.get_default_graph()\n",
    "    \n",
    "with tf.Session() as sess:    \n",
    "    for i in df.imageno:\n",
    "        feat = read_image(img_path+\"/\"+i+\".jpg\")\n",
    "        #Here activations extracted from the last fully connected layers are used as features\n",
    "        fc7 = sess.run(graph.get_tensor_by_name(\"import/Relu_1:0\"), feed_dict={images:feat})      \n",
    "        fc7=np.squeeze(fc7)\n",
    "        final_array_test.append(fc7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving the features extracted for the images\n",
    "import pickle\n",
    "pickle.dump(final_array_test, open( \"image_feature_train\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
