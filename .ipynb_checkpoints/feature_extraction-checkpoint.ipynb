{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import skimage\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "import tensorflow.python.platform\n",
    "from keras.preprocessing import sequence\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Give csv of the dataset for which feature extraction has to be performed\n",
    "df = pd.read_csv('/home/neha/sem8/AMP/assignment-2/vqa assignment/VQAMed2018Valid/VQAMed2018Valid-QA.csv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ATM-02-80-g002</td>\n",
       "      <td>what does thorax ct show?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AJNS-8-48-g001</td>\n",
       "      <td>where does the ct scan show the hematoma?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1477-7819-2-41-1</td>\n",
       "      <td>what does the ct scan show?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>iranjradiol-10-99-g001</td>\n",
       "      <td>what does the mri demonstrate?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tanaffos-10-072-g001</td>\n",
       "      <td>what does the ct scan of the chest show?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                       1                                          2\n",
       "0  1          ATM-02-80-g002                  what does thorax ct show?\n",
       "1  2          AJNS-8-48-g001  where does the ct scan show the hematoma?\n",
       "2  3        1477-7819-2-41-1                what does the ct scan show?\n",
       "3  4  iranjradiol-10-99-g001             what does the mri demonstrate?\n",
       "4  5    Tanaffos-10-072-g001   what does the ct scan of the chest show?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[[0,1,2]]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns=['Serialno','imageno','question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to remove inputs where answers span across multiple columns  \n",
    "boolmat=[]\n",
    "for i in range(0,len(df)):\n",
    "    boolmat.append(df['question'].iloc[i][len(df['question'].iloc[i])-1]=='?')\n",
    "df=df[boolmat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path to VGG model \n",
    "vgg_path = './vqa assignment/model/vgg16-20160129.tfmodel'\n",
    "#path to directory that contains images\n",
    "img_path='./vqa assignment/VQAMed2018Valid/VQAMed2018Valid-images'\n",
    "def crop_image(x, target_height=227, target_width=227, as_float=True):\n",
    "    image = cv2.imread(x)\n",
    "    if as_float:\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "    if len(image.shape) == 2:\n",
    "        image = np.tile(image[:,:,None], 3)\n",
    "    elif len(image.shape) == 4:\n",
    "        image = image[:,:,:,0]\n",
    "\n",
    "    height, width, rgb = image.shape\n",
    "    if width == height:\n",
    "        resized_image = cv2.resize(image, (target_height,target_width))\n",
    "\n",
    "    elif height < width:\n",
    "        resized_image = cv2.resize(image, (int(width * float(target_height)/height), target_width))\n",
    "        cropping_length = int((resized_image.shape[1] - target_height) / 2)\n",
    "        resized_image = resized_image[:,cropping_length:resized_image.shape[1] - cropping_length]\n",
    "\n",
    "    else:\n",
    "        resized_image = cv2.resize(image, (target_height, int(height * float(target_width) / width)))\n",
    "        cropping_length = int((resized_image.shape[0] - target_width) / 2)\n",
    "        resized_image = resized_image[cropping_length:resized_image.shape[0] - cropping_length,:]\n",
    "\n",
    "    return cv2.resize(resized_image, (target_height, target_width))\n",
    "\n",
    "def read_image(path):\n",
    "    img = crop_image(path, target_height=224, target_width=224)\n",
    "    if img.shape[2] == 4:\n",
    "        img = img[:,:,:3]\n",
    "    img = img[None, ...]\n",
    "    return img\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with open(vgg_path,'rb') as f:\n",
    "        fileContent = f.read()\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(fileContent)\n",
    "final_array_test = []\n",
    "images = tf.placeholder(\"float32\", [1, 224, 224, 3])\n",
    "tf.import_graph_def(graph_def, input_map={\"images\":images})\n",
    "graph = tf.get_default_graph()\n",
    "    \n",
    "with tf.Session() as sess:    \n",
    "    for i in df.imageno:\n",
    "        feat = read_image(img_path+\"/\"+i+\".jpg\")\n",
    "        #Here activations extracted from the last fully connected layers are used as features\n",
    "        fc7 = sess.run(graph.get_tensor_by_name(\"import/Relu_1:0\"), feed_dict={images:feat})      \n",
    "        fc7=np.squeeze(fc7)\n",
    "        final_array_test.append(fc7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving the features extracted for the images\n",
    "import pickle\n",
    "pickle.dump(final_array_test, open( \"image_feature_train\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
